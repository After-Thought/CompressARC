# Command line arguments
cli_args:
  split: "training"
  task: "28e73c20"
  output_dir: "outputs/large_model/"
  device: "cuda:0"

# Model configuration
model:
  n_layers: 12
  share_up_dim: 16
  share_down_dim: 8
  decoding_dim: 4
  softmax_dim: 2
  cummax_dim: 4
  shift_dim: 4
  nonlinear_dim: 16

# Optimizer configuration
optimizer:
  lr: 0.01
  betas: [0.5, 0.9]

# Training configuration
training:
  n_iterations: 1500
  plot_interval: 50 